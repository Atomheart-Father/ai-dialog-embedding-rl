"""
å¥–åŠ±è®¡ç®—å™¨
å®ç°å¤šç»´åº¦å¥–åŠ±å‡½æ•°ï¼Œç”¨äºå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
"""
import re
import math
from typing import Dict, List
import logging
from config import rl_config
from models import model_manager

logger = logging.getLogger(__name__)

class RewardCalculator:
    """å¥–åŠ±è®¡ç®—å™¨"""
    
    def __init__(self):
        self.quality_weight = rl_config.quality_reward_weight
        self.compression_weight = rl_config.compression_reward_weight  
        self.coherence_weight = rl_config.coherence_reward_weight
        
        logger.info("ğŸ¯ å¥–åŠ±è®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def calculate_total_reward(self, 
                             original_state,
                             action: int,
                             compressed_summary: str,
                             dialog_response: str,
                             user_input: str) -> float:
        """è®¡ç®—æ€»å¥–åŠ±"""
        
        # 1. å›ç­”è´¨é‡å¥–åŠ±
        quality_reward = self._calculate_quality_reward(
            dialog_response, user_input, compressed_summary
        )
        
        # 2. å‹ç¼©æ•ˆç‡å¥–åŠ±
        compression_reward = self._calculate_compression_reward(
            original_state, compressed_summary
        )
        
        # 3. è¿è´¯æ€§å¥–åŠ±
        coherence_reward = self._calculate_coherence_reward(
            original_state.history, compressed_summary, dialog_response
        )
        
        # åŠ æƒæ€»å¥–åŠ±
        total_reward = (
            self.quality_weight * quality_reward +
            self.compression_weight * compression_reward +
            self.coherence_weight * coherence_reward
        )
        
        logger.debug(f"å¥–åŠ±åˆ†è§£: è´¨é‡={quality_reward:.3f}, å‹ç¼©={compression_reward:.3f}, "
                    f"è¿è´¯={coherence_reward:.3f}, æ€»è®¡={total_reward:.3f}")
        
        return total_reward
    
    def _calculate_quality_reward(self, 
                                dialog_response: str, 
                                user_input: str,
                                compressed_summary: str) -> float:
        """è®¡ç®—å›ç­”è´¨é‡å¥–åŠ±"""
        if not dialog_response.strip():
            return -1.0  # ç©ºå›å¤ä¸¥é‡æƒ©ç½š
        
        quality_score = 0.0
        
        # 1. é•¿åº¦åˆç†æ€§ (é¿å…è¿‡çŸ­æˆ–è¿‡é•¿å›å¤)
        response_length = len(dialog_response)
        if 10 <= response_length <= 500:
            quality_score += 0.3
        elif response_length < 10:
            quality_score -= 0.5  # è¿‡çŸ­æƒ©ç½š
        elif response_length > 1000:
            quality_score -= 0.3  # è¿‡é•¿è½»å¾®æƒ©ç½š
        
        # 2. ç›¸å…³æ€§æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        user_keywords = self._extract_keywords(user_input)
        response_keywords = self._extract_keywords(dialog_response)
        
        if user_keywords and response_keywords:
            # è®¡ç®—å…³é”®è¯é‡å åº¦
            overlap = len(set(user_keywords) & set(response_keywords))
            relevance_score = min(1.0, overlap / len(user_keywords))
            quality_score += 0.4 * relevance_score
        
        # 3. æµç•…æ€§æ£€æŸ¥ï¼ˆåŸºäºå¥å­ç»“æ„ï¼‰
        if self._check_fluency(dialog_response):
            quality_score += 0.3
        
        return max(-1.0, min(1.0, quality_score))  # é™åˆ¶åœ¨[-1, 1]èŒƒå›´
    
    def _calculate_compression_reward(self, original_state, compressed_summary: str) -> float:
        """è®¡ç®—å‹ç¼©æ•ˆç‡å¥–åŠ±"""
        if not compressed_summary.strip():
            return -0.5  # ç©ºæ‘˜è¦æƒ©ç½š
        
        # è®¡ç®—å‹ç¼©æ¯”
        original_tokens = original_state.token_count
        summary_tokens = model_manager.count_tokens(compressed_summary)
        
        if original_tokens == 0:
            return 0.0
        
        compression_ratio = summary_tokens / original_tokens
        
        # ç†æƒ³å‹ç¼©æ¯”åœ¨ 0.2-0.4 ä¹‹é—´
        if 0.2 <= compression_ratio <= 0.4:
            ratio_reward = 1.0
        elif compression_ratio < 0.2:
            # å‹ç¼©è¿‡åº¦ï¼Œå¯èƒ½ä¸¢å¤±ä¿¡æ¯
            ratio_reward = 0.5
        elif compression_ratio > 0.6:
            # å‹ç¼©ä¸è¶³
            ratio_reward = 0.3
        else:
            ratio_reward = 0.7
        
        # TokenèŠ‚çœå¥–åŠ±
        tokens_saved = original_tokens - summary_tokens
        save_reward = min(1.0, tokens_saved / 1000)  # æ¯èŠ‚çœ1000 tokenså¥–åŠ±1.0
        
        return 0.6 * ratio_reward + 0.4 * save_reward
    
    def _calculate_coherence_reward(self, 
                                  history: List[Dict], 
                                  compressed_summary: str,
                                  dialog_response: str) -> float:
        """è®¡ç®—è¿è´¯æ€§å¥–åŠ±"""
        coherence_score = 0.0
        
        # 1. æ‘˜è¦ä¸å†å²çš„ä¸€è‡´æ€§
        if history and compressed_summary:
            history_text = " ".join([turn['content'] for turn in history[-5:]])
            summary_keywords = set(self._extract_keywords(compressed_summary))
            history_keywords = set(self._extract_keywords(history_text))
            
            if history_keywords:
                consistency = len(summary_keywords & history_keywords) / len(history_keywords)
                coherence_score += 0.5 * consistency
        
        # 2. å›å¤ä¸ä¸Šä¸‹æ–‡çš„è¿è´¯æ€§
        if history and dialog_response:
            recent_context = " ".join([turn['content'] for turn in history[-2:]])
            context_keywords = set(self._extract_keywords(recent_context))
            response_keywords = set(self._extract_keywords(dialog_response))
            
            if context_keywords:
                context_coherence = len(context_keywords & response_keywords) / len(context_keywords)
                coherence_score += 0.3 * context_coherence
        
        # 3. ä¸»é¢˜è¿ç»­æ€§ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
        if self._check_topic_continuity(history, dialog_response):
            coherence_score += 0.2
        
        return max(0.0, min(1.0, coherence_score))
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        if not text:
            return []
        
        # ç®€å•çš„å…³é”®è¯æå–ï¼šå»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œæå–é•¿åº¦å¤§äº2çš„è¯
        words = re.findall(r'\b\w{3,}\b', text.lower())
        
        # è¿‡æ»¤å¸¸è§åœç”¨è¯
        stop_words = {
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬',
            'è¿™', 'é‚£', 'è¿™ä¸ª', 'é‚£ä¸ª', 'æœ‰', 'æ²¡æœ‰', 'å¯ä»¥', 'ä¸èƒ½', 'ä¼š', 'ä¸ä¼š',
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has'
        }
        
        keywords = [word for word in words if word not in stop_words]
        return keywords[:10]  # è¿”å›å‰10ä¸ªå…³é”®è¯
    
    def _check_fluency(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æµç•…æ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        if not text.strip():
            return False
        
        # ç®€å•çš„æµç•…æ€§æŒ‡æ ‡
        sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if not sentences:
            return False
        
        # æ£€æŸ¥å¹³å‡å¥å­é•¿åº¦
        avg_length = sum(len(s.split()) for s in sentences) / len(sentences)
        
        # åˆç†çš„å¥å­é•¿åº¦èŒƒå›´
        return 3 <= avg_length <= 30
    
    def _check_topic_continuity(self, history: List[Dict], response: str) -> bool:
        """æ£€æŸ¥ä¸»é¢˜è¿ç»­æ€§ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        if not history or not response:
            return True  # é»˜è®¤è®¤ä¸ºè¿è´¯
        
        # æå–æœ€è¿‘å‡ è½®å¯¹è¯çš„å…³é”®è¯
        recent_keywords = set()
        for turn in history[-3:]:
            recent_keywords.update(self._extract_keywords(turn['content']))
        
        response_keywords = set(self._extract_keywords(response))
        
        # å¦‚æœå›å¤åŒ…å«æœ€è¿‘å¯¹è¯çš„å…³é”®è¯ï¼Œè®¤ä¸ºä¸»é¢˜è¿ç»­
        if recent_keywords and response_keywords:
            overlap_ratio = len(recent_keywords & response_keywords) / len(recent_keywords)
            return overlap_ratio > 0.1  # è‡³å°‘10%çš„å…³é”®è¯é‡å 
        
        return True
    
    def calculate_episode_bonus(self, episode_stats: Dict) -> float:
        """è®¡ç®—episodeçº§åˆ«çš„å¥–åŠ±åŠ æˆ"""
        bonus = 0.0
        
        # 1. å¯¹è¯é•¿åº¦å¥–åŠ±ï¼ˆé¼“åŠ±é•¿å¯¹è¯ï¼‰
        steps = episode_stats.get('steps', 0)
        if steps > 10:
            bonus += 0.1 * math.log(steps / 10)
        
        # 2. å‹ç¼©æ•ˆç‡å¥–åŠ±
        if episode_stats.get('compression_count', 0) > 0:
            avg_compression_ratio = episode_stats.get('avg_compression_ratio', 0.5)
            if 0.2 <= avg_compression_ratio <= 0.4:
                bonus += 0.2
        
        return bonus

# å…¨å±€å¥–åŠ±è®¡ç®—å™¨å®ä¾‹
reward_calculator = RewardCalculator() 