"""
æµ‹è¯•ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹hidden statesçš„å‹ç¼©æ–¹æ¡ˆ
å±•ç¤ºå¤šç§èåˆç­–ç•¥çš„æ•ˆæœå¯¹æ¯”
"""
import sys
import time
import torch
import numpy as np
from typing import List, Dict

# å¯é€‰ä¾èµ–å¯¼å…¥
try:
    import matplotlib.pyplot as plt
    PLOTTING_AVAILABLE = True
except ImportError:
    PLOTTING_AVAILABLE = False
    print("Warning: matplotlib not available. Some visualization features will be disabled.")

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from direct_embedding_compressor import direct_compressor
from models import model_manager

def test_hidden_state_extraction():
    """æµ‹è¯•hidden stateæå–åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•1: Hidden Stateæå–")
    
    test_dialogs = [
        "ç”¨æˆ·: æˆ‘æƒ³å­¦ä¹ æœºå™¨å­¦ä¹ \nåŠ©æ‰‹: å»ºè®®ä»PythonåŸºç¡€å¼€å§‹å­¦ä¹ ",
        "ç”¨æˆ·: æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\nåŠ©æ‰‹: æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é›†",
        "ç”¨æˆ·: å¼ºåŒ–å­¦ä¹ é€‚åˆä»€ä¹ˆåœºæ™¯ï¼Ÿ\nåŠ©æ‰‹: é€‚åˆå†³ç­–ä¼˜åŒ–å’Œæ¸¸æˆAIç­‰åœºæ™¯"
    ]
    
    for i, dialog in enumerate(test_dialogs):
        print(f"\n  å¯¹è¯ {i+1}: {dialog[:30]}...")
        
        start_time = time.time()
        hidden_states = direct_compressor.extract_dialog_hidden_states(dialog)
        end_time = time.time()
        
        print(f"    æå–æ—¶é—´: {end_time-start_time:.3f}s")
        print(f"    æå–çš„states: {list(hidden_states.keys())}")
        
        if 'combined' in hidden_states:
            combined = hidden_states['combined']
            print(f"    Combined state shape: {combined.shape}")
            print(f"    State norm: {torch.norm(combined):.3f}")
            print(f"    State mean: {torch.mean(combined):.3f}")
    
    print("âœ… Hidden Stateæå–æµ‹è¯•å®Œæˆ\n")

def test_state_bank_operations():
    """æµ‹è¯•State Bankæ“ä½œ"""
    print("ğŸ§ª æµ‹è¯•2: State Bankæ“ä½œ")
    
    # æ¨¡æ‹Ÿå†å²å¯¹è¯
    history = [
        {'role': 'user', 'content': 'æˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹'},
        {'role': 'assistant', 'content': 'å»ºè®®ä»åŸºç¡€è¯­æ³•å¼€å§‹ï¼Œç„¶åå­¦ä¹ æ•°æ®ç»“æ„'},
        {'role': 'user', 'content': 'æœºå™¨å­¦ä¹ éœ€è¦ä»€ä¹ˆæ•°å­¦åŸºç¡€ï¼Ÿ'},
        {'role': 'assistant', 'content': 'ä¸»è¦éœ€è¦çº¿æ€§ä»£æ•°ã€æ¦‚ç‡è®ºå’Œå¾®ç§¯åˆ†'},
        {'role': 'user', 'content': 'æ·±åº¦å­¦ä¹ æ¡†æ¶å“ªä¸ªå¥½ï¼Ÿ'},
        {'role': 'assistant', 'content': 'PyTorchå’ŒTensorFlowéƒ½å¾ˆä¸é”™ï¼Œæ¨èä»PyTorchå¼€å§‹'}
    ]
    
    print(f"  å¤„ç† {len(history)//2} è½®å¯¹è¯...")
    
    # å‹ç¼©å†å²ä¸ºstates
    compressed_states = direct_compressor.compress_history_to_states(history)
    
    print(f"  å‹ç¼©å¾—åˆ° {len(compressed_states)} ä¸ªstateæ¡ç›®")
    
    for i, state_entry in enumerate(compressed_states):
        print(f"    è½®æ¬¡{i+1}: {state_entry['summary']}")
        print(f"      States: {list(state_entry['states'].keys())}")
    
    # æµ‹è¯•æ£€ç´¢
    print("\n  ğŸ” æµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢:")
    query_text = "æˆ‘æƒ³äº†è§£æ·±åº¦å­¦ä¹ "
    query_states = direct_compressor.extract_dialog_hidden_states(f"ç”¨æˆ·: {query_text}")
    query_state = query_states['combined']
    
    relevant = direct_compressor.state_bank.retrieve_relevant_states(query_state, top_k=3)
    print(f"    æŸ¥è¯¢: {query_text}")
    print(f"    æ‰¾åˆ° {len(relevant)} ä¸ªç›¸å…³states:")
    
    for i, entry in enumerate(relevant):
        print(f"      {i+1}. {entry['metadata']['summary']}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    bank_stats = direct_compressor.state_bank.get_state_summary()
    print(f"\n  ğŸ“Š State Bankç»Ÿè®¡:")
    for key, value in bank_stats.items():
        print(f"    {key}: {value}")
    
    print("âœ… State Bankæ“ä½œæµ‹è¯•å®Œæˆ\n")

def test_fusion_strategies():
    """æµ‹è¯•ä¸åŒçš„èåˆç­–ç•¥"""
    print("ğŸ§ª æµ‹è¯•3: èåˆç­–ç•¥å¯¹æ¯”")
    
    # å…ˆå¡«å……ä¸€äº›å†å²æ•°æ®
    history = [
        {'role': 'user', 'content': 'ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ'},
        {'role': 'assistant', 'content': 'æœºå™¨å­¦ä¹ æ˜¯è®©è®¡ç®—æœºä»æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ çš„æŠ€æœ¯'},
        {'role': 'user', 'content': 'ç¥ç»ç½‘ç»œæ˜¯ä»€ä¹ˆï¼Ÿ'},
        {'role': 'assistant', 'content': 'ç¥ç»ç½‘ç»œæ˜¯æ¨¡æ‹Ÿå¤§è„‘ç¥ç»å…ƒå·¥ä½œçš„è®¡ç®—æ¨¡å‹'},
    ]
    
    direct_compressor.compress_history_to_states(history)
    
    # æµ‹è¯•æŸ¥è¯¢
    test_query = "æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„å…³ç³»"
    
    strategies = ['attention', 'weighted_sum', 'concatenation', 'interpolation']
    results = {}
    
    for strategy in strategies:
        print(f"\n  ğŸ”§ æµ‹è¯•èåˆç­–ç•¥: {strategy}")
        
        # åˆ‡æ¢ç­–ç•¥
        direct_compressor.switch_fusion_strategy(strategy)
        
        start_time = time.time()
        enhanced_prompt, metadata = direct_compressor.generate_enhanced_context(test_query)
        end_time = time.time()
        
        results[strategy] = {
            'time': end_time - start_time,
            'metadata': metadata,
            'prompt_length': len(enhanced_prompt)
        }
        
        print(f"    å¤„ç†æ—¶é—´: {results[strategy]['time']:.3f}s")
        print(f"    æ˜¯å¦ä½¿ç”¨èåˆ: {metadata['fusion_used']}")
        if metadata['fusion_used']:
            print(f"    ä¸Šä¸‹æ–‡statesæ•°: {metadata['num_context_states']}")
            print(f"    å¢å¼ºstate norm: {metadata['enhanced_state_norm']:.3f}")
        print(f"    ç”Ÿæˆprompté•¿åº¦: {results[strategy]['prompt_length']} å­—ç¬¦")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„promptç‰‡æ®µ
        print(f"    ç”Ÿæˆçš„prompté¢„è§ˆ:")
        lines = enhanced_prompt.split('\n')
        for line in lines[:4]:
            print(f"      {line}")
        if len(lines) > 4:
            print(f"      ... (å…±{len(lines)}è¡Œ)")
    
    # æ€§èƒ½å¯¹æ¯”
    print(f"\n  ğŸ“Š èåˆç­–ç•¥æ€§èƒ½å¯¹æ¯”:")
    for strategy, result in results.items():
        print(f"    {strategy:15s}: {result['time']:.3f}s, {result['prompt_length']:4d} chars")
    
    print("âœ… èåˆç­–ç•¥æµ‹è¯•å®Œæˆ\n")

def test_compression_efficiency():
    """æµ‹è¯•å‹ç¼©æ•ˆç‡"""
    print("ğŸ§ª æµ‹è¯•4: å‹ç¼©æ•ˆç‡åˆ†æ")
    
    # åˆ›å»ºæ›´å¤šçš„æµ‹è¯•æ•°æ®
    extended_history = []
    topics = [
        ("Pythonç¼–ç¨‹", "å­¦ä¹ åŸºç¡€è¯­æ³•å’Œæ•°æ®ç»“æ„"),
        ("æœºå™¨å­¦ä¹ ", "ç†è§£ç®—æ³•å’Œæ¨¡å‹è®­ç»ƒ"),
        ("æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œå’Œåå‘ä¼ æ’­"),
        ("å¼ºåŒ–å­¦ä¹ ", "æ™ºèƒ½ä½“å’Œç¯å¢ƒäº¤äº’"),
        ("æ•°æ®ç§‘å­¦", "æ•°æ®åˆ†æå’Œå¯è§†åŒ–"),
        ("Webå¼€å‘", "å‰ç«¯å’Œåç«¯æŠ€æœ¯"),
        ("ç®—æ³•è®¾è®¡", "æ—¶é—´å¤æ‚åº¦å’Œç©ºé—´å¤æ‚åº¦")
    ]
    
    for i, (topic, response) in enumerate(topics):
        extended_history.extend([
            {'role': 'user', 'content': f'æˆ‘æƒ³å­¦ä¹ {topic}ï¼Œåº”è¯¥æ€ä¹ˆå¼€å§‹ï¼Ÿ'},
            {'role': 'assistant', 'content': f'å…³äº{topic}ï¼Œå»ºè®®{response}ï¼Œç„¶åé€æ­¥æ·±å…¥å®è·µã€‚'}
        ])
    
    print(f"  å¤„ç† {len(extended_history)//2} è½®æ‰©å±•å¯¹è¯...")
    
    # å‹ç¼©æ‰€æœ‰å†å²
    start_time = time.time()
    compressed_states = direct_compressor.compress_history_to_states(extended_history)
    compression_time = time.time() - start_time
    
    # è®¡ç®—å‹ç¼©ç»Ÿè®¡
    stats = direct_compressor.get_compression_statistics()
    
    print(f"  â±ï¸  å‹ç¼©æ—¶é—´: {compression_time:.3f}s")
    print(f"  ğŸ“¦ å‹ç¼©ç»Ÿè®¡:")
    
    bank_info = stats['state_bank_info']
    efficiency = stats['compression_efficiency']
    
    print(f"    æ€»statesæ•°: {bank_info.get('total_states', 0)}")
    print(f"    çŠ¶æ€ç»´åº¦: {bank_info.get('state_dimension', 0)}")
    print(f"    å†…å­˜ä½¿ç”¨: {bank_info.get('memory_usage_mb', 0):.2f} MB")
    
    if efficiency:
        print(f"    å‹ç¼©æ¯”: {efficiency.get('compression_ratio', 1.0):.3f}")
        print(f"    å†…å­˜èŠ‚çœ: {efficiency.get('memory_savings_mb', 0):.2f} MB")
    
    # æµ‹è¯•æ£€ç´¢æ€§èƒ½
    test_queries = [
        "æˆ‘æƒ³å­¦ä¹ ç¼–ç¨‹",
        "æœºå™¨å­¦ä¹ ç®—æ³•æœ‰å“ªäº›ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ çš„åº”ç”¨åœºæ™¯",
        "æ•°æ®åˆ†æçš„å·¥å…·"
    ]
    
    print(f"\n  ğŸ” æ£€ç´¢æ€§èƒ½æµ‹è¯•:")
    retrieval_times = []
    
    for query in test_queries:
        start_time = time.time()
        enhanced_prompt, metadata = direct_compressor.generate_enhanced_context(query)
        retrieval_time = time.time() - start_time
        retrieval_times.append(retrieval_time)
        
        print(f"    æŸ¥è¯¢: {query[:20]}... -> {retrieval_time:.3f}s")
    
    avg_retrieval_time = np.mean(retrieval_times)
    print(f"    å¹³å‡æ£€ç´¢æ—¶é—´: {avg_retrieval_time:.3f}s")
    
    print("âœ… å‹ç¼©æ•ˆç‡æµ‹è¯•å®Œæˆ\n")

def test_context_enhancement():
    """æµ‹è¯•ä¸Šä¸‹æ–‡å¢å¼ºæ•ˆæœ"""
    print("ğŸ§ª æµ‹è¯•5: ä¸Šä¸‹æ–‡å¢å¼ºæ•ˆæœ")
    
    # å»ºç«‹ä¸€äº›å†å²å¯¹è¯ä¸Šä¸‹æ–‡
    context_history = [
        {'role': 'user', 'content': 'æˆ‘æ˜¯ä¸€ä¸ªåˆå­¦è€…ï¼Œæƒ³ä»é›¶å¼€å§‹å­¦ä¹ ç¼–ç¨‹'},
        {'role': 'assistant', 'content': 'å¾ˆå¥½ï¼å¯¹äºåˆå­¦è€…ï¼Œæˆ‘å»ºè®®ä»Pythonå¼€å§‹ï¼Œå› ä¸ºè¯­æ³•ç®€å•æ˜“æ‡‚'},
        {'role': 'user', 'content': 'æˆ‘åº”è¯¥å…ˆå­¦ä¹ å“ªäº›ç¼–ç¨‹æ¦‚å¿µï¼Ÿ'},
        {'role': 'assistant', 'content': 'å»ºè®®å…ˆå­¦ä¹ å˜é‡ã€å¾ªç¯ã€æ¡ä»¶åˆ¤æ–­ç­‰åŸºç¡€æ¦‚å¿µ'},
        {'role': 'user', 'content': 'æœ‰ä»€ä¹ˆå¥½çš„å­¦ä¹ èµ„æºæ¨èå—ï¼Ÿ'},
        {'role': 'assistant', 'content': 'æ¨èã€ŠPythonç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µã€‹è¿™æœ¬ä¹¦ï¼Œè¿˜æœ‰åœ¨çº¿å¹³å°å¦‚Codecademy'}
    ]
    
    # å‹ç¼©å†å²
    direct_compressor.compress_history_to_states(context_history)
    
    # æµ‹è¯•æ–°çš„æŸ¥è¯¢
    new_queries = [
        "æˆ‘æƒ³ç»§ç»­å­¦ä¹ æ•°æ®ç»“æ„",  # ç›¸å…³ï¼šç¼–ç¨‹å­¦ä¹ 
        "æ¨èä¸€äº›Pythoné¡¹ç›®ç»ƒä¹ ", # ç›¸å…³ï¼šPythonå­¦ä¹ 
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",       # ä¸ç›¸å…³ï¼šå¤©æ°”
        "æˆ‘æƒ³å­¦ä¹ æœºå™¨å­¦ä¹ ç®—æ³•"    # éƒ¨åˆ†ç›¸å…³ï¼šå­¦ä¹ ä½†ä¸æ˜¯ç¼–ç¨‹åŸºç¡€
    ]
    
    print("  æµ‹è¯•ä¸åŒç±»å‹æŸ¥è¯¢çš„ä¸Šä¸‹æ–‡å¢å¼ºæ•ˆæœ:\n")
    
    for i, query in enumerate(new_queries):
        print(f"  æŸ¥è¯¢ {i+1}: {query}")
        
        # ç”Ÿæˆå¢å¼ºä¸Šä¸‹æ–‡
        enhanced_prompt, metadata = direct_compressor.generate_enhanced_context(query)
        
        print(f"    èåˆçŠ¶æ€: {'æ˜¯' if metadata['fusion_used'] else 'å¦'}")
        
        if metadata['fusion_used']:
            print(f"    èåˆç­–ç•¥: {metadata['fusion_strategy']}")
            print(f"    ç›¸å…³å†å²: {len(metadata['relevant_turns'])} æ¡")
            print(f"    ç›¸å…³å†…å®¹: {metadata['relevant_turns']}")
            print(f"    å¢å¼ºå¼ºåº¦: {metadata['enhanced_state_norm']:.3f}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„å¢å¼ºprompt
        print(f"    å¢å¼ºåçš„prompt:")
        lines = enhanced_prompt.split('\n')
        for line in lines[:6]:  # æ˜¾ç¤ºå‰6è¡Œ
            print(f"      {line}")
        if len(lines) > 6:
            print(f"      ... (å…±{len(lines)}è¡Œ)")
        
        print()  # ç©ºè¡Œåˆ†éš”
    
    print("âœ… ä¸Šä¸‹æ–‡å¢å¼ºæµ‹è¯•å®Œæˆ\n")

def visualize_state_similarities():
    """å¯è§†åŒ–stateç›¸ä¼¼åº¦"""
    print("ğŸ§ª æµ‹è¯•6: Stateç›¸ä¼¼åº¦å¯è§†åŒ–")
    
    try:
        # è·å–å½“å‰state bankä¸­çš„æ‰€æœ‰states
        state_bank = direct_compressor.state_bank.state_bank
        
        if len(state_bank) < 2:
            print("  State bankä¸­æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        # æå–æ‰€æœ‰states
        states = [entry['state'].detach().cpu().numpy() for entry in state_bank]
        summaries = [entry['metadata']['summary'] for entry in state_bank]
        
        # è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
        n = len(states)
        similarity_matrix = np.zeros((n, n))
        
        for i in range(n):
            for j in range(n):
                if i != j:
                    state_i = torch.tensor(states[i])
                    state_j = torch.tensor(states[j])
                    sim = torch.nn.functional.cosine_similarity(state_i, state_j, dim=0)
                    similarity_matrix[i][j] = sim.item()
                else:
                    similarity_matrix[i][j] = 1.0
        
        # ç®€å•çš„ç›¸ä¼¼åº¦ç»Ÿè®¡
        print(f"  ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ ({n} ä¸ªstates):")
        print(f"    å¹³å‡ç›¸ä¼¼åº¦: {np.mean(similarity_matrix[similarity_matrix < 1.0]):.3f}")
        print(f"    æœ€å¤§ç›¸ä¼¼åº¦: {np.max(similarity_matrix[similarity_matrix < 1.0]):.3f}")
        print(f"    æœ€å°ç›¸ä¼¼åº¦: {np.min(similarity_matrix[similarity_matrix < 1.0]):.3f}")
        
        # æ‰¾å‡ºæœ€ç›¸ä¼¼çš„pair
        max_sim_idx = np.unravel_index(
            np.argmax(similarity_matrix * (1 - np.eye(n))), 
            similarity_matrix.shape
        )
        
        print(f"    æœ€ç›¸ä¼¼çš„å¯¹è¯:")
        print(f"      A: {summaries[max_sim_idx[0]]}")
        print(f"      B: {summaries[max_sim_idx[1]]}")
        print(f"      ç›¸ä¼¼åº¦: {similarity_matrix[max_sim_idx]:.3f}")
    
    except Exception as e:
        print(f"  å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    
    print("âœ… ç›¸ä¼¼åº¦å¯è§†åŒ–å®Œæˆ\n")

def run_comprehensive_test():
    """è¿è¡Œå®Œæ•´çš„ç›´æ¥embeddingæµ‹è¯•"""
    print("ğŸš€ å¼€å§‹ç›´æ¥Embeddingå‹ç¼©ç»¼åˆæµ‹è¯•")
    print("=" * 60)
    
    # åŠ è½½æ¨¡å‹
    print("ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹...")
    try:
        model_manager.load_models()
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿›è¡Œæµ‹è¯•")
    
    print("\n" + "=" * 60)
    
    # ä¾æ¬¡è¿è¡Œå„é¡¹æµ‹è¯•
    test_hidden_state_extraction()
    test_state_bank_operations()
    test_fusion_strategies()
    test_compression_efficiency()
    test_context_enhancement()
    visualize_state_similarities()
    
    # æœ€ç»ˆæ€»ç»“
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ“‹ ç›´æ¥Embeddingå‹ç¼©æ–¹æ¡ˆç‰¹ç‚¹:")
    print("âœ… ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹çš„hidden states")
    print("âœ… å¤šå±‚stateæå–å’Œèåˆ")
    print("âœ… å››ç§èåˆç­–ç•¥: attention, weighted_sum, concatenation, interpolation")
    print("âœ… æ™ºèƒ½çš„ç›¸ä¼¼åº¦æ£€ç´¢")
    print("âœ… é«˜æ•ˆçš„å†…å­˜ä½¿ç”¨")
    print("âœ… æ— éœ€é¢å¤–çš„embeddingæ¨¡å‹")
    print("\nğŸ¯ è¿™ä¸ªæ–¹æ¡ˆå®Œå…¨ç¬¦åˆæ‚¨çš„è¦æ±‚ï¼šç›´æ¥ç”¨å¤§æ¨¡å‹å†…éƒ¨çŠ¶æ€å‹ç¼©ä¸Šä¸‹æ–‡ï¼")

if __name__ == "__main__":
    run_comprehensive_test() 