{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# å¼ºåŒ–å­¦ä¹ å¯¹è¯ç³»ç»Ÿå®éªŒ\n",
        "## Embedding vs æ–‡æœ¬å‹ç¼©å¯¹æ¯”å®éªŒ\n",
        "\n",
        "æœ¬å®éªŒå¯¹æ¯”å››ç§ä¸åŒçš„å‹ç¼©å’Œè®­ç»ƒç­–ç•¥ï¼š\n",
        "1. **åŸºçº¿ç»„**: æ— å‹ç¼© + æ— RLè®­ç»ƒ\n",
        "2. **æ–‡æœ¬å‹ç¼©ç»„**: æ–‡æœ¬å‹ç¼© + æ— RLè®­ç»ƒ  \n",
        "3. **Embeddingå‹ç¼©ç»„**: Embeddingå‹ç¼© + æ— RLè®­ç»ƒ\n",
        "4. **RLè®­ç»ƒç»„**: Embeddingå‹ç¼© + RLè®­ç»ƒ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Dict, Tuple\n",
        "from datetime import datetime\n",
        "\n",
        "# å¯¼å…¥é¡¹ç›®æ¨¡å—\n",
        "from models import model_manager\n",
        "from embedding_compressor import embedding_compressor\n",
        "from rl_trainer import rl_trainer\n",
        "from dialog_manager import dialog_manager\n",
        "\n",
        "print(\"ğŸš€ å¼ºåŒ–å­¦ä¹ å¯¹è¯ç³»ç»Ÿå®éªŒç¯å¢ƒåˆå§‹åŒ–å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å®éªŒé…ç½®\n",
        "EXPERIMENT_CONFIG = {\n",
        "    'test_conversations': [\n",
        "        \"æˆ‘æƒ³å­¦ä¹ æœºå™¨å­¦ä¹ ï¼Œä»å“ªé‡Œå¼€å§‹ï¼Ÿ\",\n",
        "        \"ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\", \n",
        "        \"æ·±åº¦å­¦ä¹ éœ€è¦ä»€ä¹ˆæ•°å­¦åŸºç¡€ï¼Ÿ\",\n",
        "        \"ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Ÿæœ‰å“ªäº›åº”ç”¨ï¼Ÿ\",\n",
        "        \"å¦‚ä½•è¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Ÿ\",\n",
        "        \"è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆæ€ä¹ˆè§£å†³ï¼Ÿ\",\n",
        "        \"ç‰¹å¾å·¥ç¨‹æœ‰ä»€ä¹ˆæŠ€å·§ï¼Ÿ\",\n",
        "        \"å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç®—æ³•ï¼Ÿ\"\n",
        "    ],\n",
        "    'max_turns': 8,\n",
        "    'compression_threshold': 1500,\n",
        "    'comparison_groups': [\n",
        "        'baseline',      # æ— å‹ç¼©+æ— RL\n",
        "        'text_compress', # æ–‡æœ¬å‹ç¼©+æ— RL  \n",
        "        'embed_compress',# Embeddingå‹ç¼©+æ— RL\n",
        "        'embed_rl'       # Embeddingå‹ç¼©+RL\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(f\"ğŸ“‹ å®éªŒé…ç½®: {len(EXPERIMENT_CONFIG['test_conversations'])} ä¸ªæµ‹è¯•å¯¹è¯\")\n",
        "print(f\"ğŸ“Š å¯¹æ¯”ç»„: {EXPERIMENT_CONFIG['comparison_groups']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Embeddingå‹ç¼©å®éªŒç±»\n",
        "class EmbeddingCompressionExperiment:\n",
        "    \"\"\"åŸºäºEmbeddingçš„å‹ç¼©å®éªŒ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.results = {}\n",
        "        self.compression_stats = {}\n",
        "        \n",
        "    def run_embedding_compression_test(self, test_inputs: List[str]) -> Dict:\n",
        "        \"\"\"è¿è¡Œembeddingå‹ç¼©æµ‹è¯•\"\"\"\n",
        "        print(\"ğŸ§  å¼€å§‹Embeddingå‹ç¼©å®éªŒ...\")\n",
        "        \n",
        "        results = {\n",
        "            'responses': [],\n",
        "            'compression_ratios': [],\n",
        "            'response_times': [],\n",
        "            'context_lengths': [],\n",
        "            'embedding_stats': []\n",
        "        }\n",
        "        \n",
        "        dialog_history = []\n",
        "        \n",
        "        for i, user_input in enumerate(test_inputs):\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²\n",
        "            dialog_history.append({\n",
        "                'role': 'user',\n",
        "                'content': user_input,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "            \n",
        "            # åˆ¤æ–­æ˜¯å¦éœ€è¦å‹ç¼©\n",
        "            if len(dialog_history) > 4:  # 2è½®å¯¹è¯åå¼€å§‹å‹ç¼©\n",
        "                # å‹ç¼©å†å²å¯¹è¯ä¸ºembedding\n",
        "                compressed_data = embedding_compressor.compress_history_to_embeddings(dialog_history[:-1])\n",
        "                \n",
        "                # ç”ŸæˆåŒ…å«embeddingä¿¡æ¯çš„ä¸Šä¸‹æ–‡\n",
        "                context = embedding_compressor.generate_context_with_embeddings(user_input)\n",
        "                \n",
        "                # è®¡ç®—å‹ç¼©æ¯”\n",
        "                original_tokens = sum(len(turn['content']) for turn in dialog_history) // 4\n",
        "                compressed_tokens = len(context) // 4\n",
        "                compression_ratio = compressed_tokens / original_tokens if original_tokens > 0 else 1.0\n",
        "                \n",
        "                results['compression_ratios'].append(compression_ratio)\n",
        "            else:\n",
        "                # ç›´æ¥å¯¹è¯ï¼Œæ— å‹ç¼©\n",
        "                context = f\"ç”¨æˆ·: {user_input}\\nåŠ©æ‰‹:\"\n",
        "                results['compression_ratios'].append(1.0)\n",
        "            \n",
        "            # ç”Ÿæˆå›å¤\n",
        "            if model_manager.dialog_model:\n",
        "                response = model_manager.generate_text(\n",
        "                    model=model_manager.dialog_model,\n",
        "                    prompt=context,\n",
        "                    max_new_tokens=256\n",
        "                )\n",
        "            else:\n",
        "                response = f\"æ¨¡æ‹Ÿå›å¤{i+1}: å…³äº'{user_input[:20]}...'çš„è¯¦ç»†å›ç­”\"\n",
        "            \n",
        "            end_time = time.time()\n",
        "            \n",
        "            # è®°å½•ç»“æœ\n",
        "            results['responses'].append(response)\n",
        "            results['response_times'].append(end_time - start_time)\n",
        "            results['context_lengths'].append(len(context))\n",
        "            \n",
        "            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²\n",
        "            dialog_history.append({\n",
        "                'role': 'assistant',\n",
        "                'content': response,\n",
        "                'timestamp': datetime.now().isoformat()\n",
        "            })\n",
        "            \n",
        "            print(f\"  è½®æ¬¡{i+1}: å‹ç¼©æ¯”={results['compression_ratios'][-1]:.2f}, æ—¶é—´={results['response_times'][-1]:.2f}s\")\n",
        "        \n",
        "        # è·å–embeddingç»Ÿè®¡\n",
        "        stats = embedding_compressor.get_compression_stats()\n",
        "        if stats:\n",
        "            results['embedding_stats'].append(stats)\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def compare_compression_methods(self, test_inputs: List[str]) -> Dict:\n",
        "        \"\"\"å¯¹æ¯”ä¸åŒå‹ç¼©æ–¹æ³•\"\"\"\n",
        "        print(\"ğŸ” å¯¹æ¯”å®éªŒ: Embedding vs ä¼ ç»Ÿæ–¹æ³•\")\n",
        "        \n",
        "        # 1. Embeddingå‹ç¼©\n",
        "        embedding_results = self.run_embedding_compression_test(test_inputs)\n",
        "        \n",
        "        # 2. åŸºçº¿æ–¹æ³• (æ— å‹ç¼©)\n",
        "        baseline_results = self.run_baseline_test(test_inputs)\n",
        "        \n",
        "        # 3. åˆ†æå¯¹æ¯”\n",
        "        comparison = {\n",
        "            'embedding': embedding_results,\n",
        "            'baseline': baseline_results,\n",
        "            'improvements': {\n",
        "                'avg_compression_ratio': np.mean(embedding_results['compression_ratios']),\n",
        "                'avg_response_time': np.mean(embedding_results['response_times']),\n",
        "                'context_length_reduction': (\n",
        "                    np.mean(baseline_results['context_lengths']) - \n",
        "                    np.mean(embedding_results['context_lengths'])\n",
        "                ) / np.mean(baseline_results['context_lengths'])\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        return comparison\n",
        "    \n",
        "    def run_baseline_test(self, test_inputs: List[str]) -> Dict:\n",
        "        \"\"\"è¿è¡ŒåŸºçº¿æµ‹è¯•(æ— å‹ç¼©)\"\"\"\n",
        "        print(\"ğŸ“Š åŸºçº¿å®éªŒ(æ— å‹ç¼©)...\")\n",
        "        \n",
        "        results = {\n",
        "            'responses': [],\n",
        "            'compression_ratios': [],\n",
        "            'response_times': [],\n",
        "            'context_lengths': []\n",
        "        }\n",
        "        \n",
        "        full_context = \"\"\n",
        "        \n",
        "        for i, user_input in enumerate(test_inputs):\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # ç®€å•æ‹¼æ¥å†å²\n",
        "            full_context += f\"ç”¨æˆ·: {user_input}\\n\"\n",
        "            \n",
        "            if model_manager.dialog_model:\n",
        "                response = model_manager.generate_text(\n",
        "                    model=model_manager.dialog_model,\n",
        "                    prompt=full_context + \"åŠ©æ‰‹:\",\n",
        "                    max_new_tokens=256\n",
        "                )\n",
        "            else:\n",
        "                response = f\"åŸºçº¿å›å¤{i+1}: å…³äº'{user_input[:20]}...'çš„åŸºç¡€å›ç­”\"\n",
        "            \n",
        "            full_context += f\"åŠ©æ‰‹: {response}\\n\"\n",
        "            \n",
        "            end_time = time.time()\n",
        "            \n",
        "            results['responses'].append(response)\n",
        "            results['compression_ratios'].append(1.0)  # æ— å‹ç¼©\n",
        "            results['response_times'].append(end_time - start_time)\n",
        "            results['context_lengths'].append(len(full_context))\n",
        "            \n",
        "        return results\n",
        "\n",
        "# åˆ›å»ºå®éªŒå®ä¾‹\n",
        "embedding_experiment = EmbeddingCompressionExperiment()\n",
        "print(\"âœ… Embeddingå‹ç¼©å®éªŒå™¨å·²åˆå§‹åŒ–\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¿è¡Œå®Œæ•´å®éªŒ\n",
        "def run_complete_experiment():\n",
        "    \"\"\"è¿è¡Œå®Œæ•´çš„å¯¹æ¯”å®éªŒ\"\"\"\n",
        "    print(\"ğŸš€ å¼€å§‹å®Œæ•´å®éªŒ...\")\n",
        "    \n",
        "    # åŠ è½½æ¨¡å‹\n",
        "    try:\n",
        "        model_manager.load_models()\n",
        "        print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
        "        print(\"ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œå®éªŒ\")\n",
        "    \n",
        "    # è¿è¡Œå¯¹æ¯”å®éªŒ\n",
        "    test_inputs = EXPERIMENT_CONFIG['test_conversations']\n",
        "    results = embedding_experiment.compare_compression_methods(test_inputs)\n",
        "    \n",
        "    # æ˜¾ç¤ºç»“æœæ‘˜è¦\n",
        "    print(\"\\nğŸ“Š å®éªŒç»“æœæ‘˜è¦:\")\n",
        "    improvements = results['improvements']\n",
        "    print(f\"  å¹³å‡å‹ç¼©æ¯”: {improvements['avg_compression_ratio']:.2f}\")\n",
        "    print(f\"  å¹³å‡å“åº”æ—¶é—´: {improvements['avg_response_time']:.3f}s\")\n",
        "    print(f\"  ä¸Šä¸‹æ–‡é•¿åº¦å‡å°‘: {improvements['context_length_reduction']:.1%}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# å¯è§†åŒ–å‡½æ•°\n",
        "def plot_experiment_results(results: Dict):\n",
        "    \"\"\"ç»˜åˆ¶å®éªŒç»“æœå›¾è¡¨\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # 1. å‹ç¼©æ¯”å¯¹æ¯”\n",
        "    axes[0,0].plot(results['embedding']['compression_ratios'], 'b-o', label='Embeddingå‹ç¼©')\n",
        "    axes[0,0].plot(results['baseline']['compression_ratios'], 'r-s', label='åŸºçº¿(æ— å‹ç¼©)')\n",
        "    axes[0,0].set_title('å‹ç¼©æ¯”å¯¹æ¯”')\n",
        "    axes[0,0].set_xlabel('å¯¹è¯è½®æ¬¡')\n",
        "    axes[0,0].set_ylabel('å‹ç¼©æ¯”')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. å“åº”æ—¶é—´å¯¹æ¯”\n",
        "    axes[0,1].plot(results['embedding']['response_times'], 'b-o', label='Embeddingå‹ç¼©')\n",
        "    axes[0,1].plot(results['baseline']['response_times'], 'r-s', label='åŸºçº¿(æ— å‹ç¼©)')\n",
        "    axes[0,1].set_title('å“åº”æ—¶é—´å¯¹æ¯”')\n",
        "    axes[0,1].set_xlabel('å¯¹è¯è½®æ¬¡')\n",
        "    axes[0,1].set_ylabel('å“åº”æ—¶é—´(ç§’)')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. ä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ¯”\n",
        "    axes[1,0].plot(results['embedding']['context_lengths'], 'b-o', label='Embeddingå‹ç¼©')\n",
        "    axes[1,0].plot(results['baseline']['context_lengths'], 'r-s', label='åŸºçº¿(æ— å‹ç¼©)')\n",
        "    axes[1,0].set_title('ä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ¯”')\n",
        "    axes[1,0].set_xlabel('å¯¹è¯è½®æ¬¡')\n",
        "    axes[1,0].set_ylabel('ä¸Šä¸‹æ–‡é•¿åº¦(å­—ç¬¦)')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. æ€§èƒ½æ”¹è¿›æ‘˜è¦\n",
        "    improvements = results['improvements']\n",
        "    metrics = ['å‹ç¼©æ¯”', 'å¹³å‡å“åº”æ—¶é—´', 'ä¸Šä¸‹æ–‡å‡å°‘']\n",
        "    values = [\n",
        "        improvements['avg_compression_ratio'],\n",
        "        improvements['avg_response_time'], \n",
        "        improvements['context_length_reduction']\n",
        "    ]\n",
        "    \n",
        "    bars = axes[1,1].bar(metrics, values, color=['skyblue', 'lightgreen', 'orange'])\n",
        "    axes[1,1].set_title('æ€§èƒ½æ”¹è¿›æŒ‡æ ‡')\n",
        "    axes[1,1].set_ylabel('æ•°å€¼')\n",
        "    \n",
        "    # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
        "    for bar, value in zip(bars, values):\n",
        "        height = bar.get_height()\n",
        "        axes[1,1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{value:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"âœ… å®éªŒå’Œå¯è§†åŒ–å‡½æ•°å·²å‡†å¤‡å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸƒâ€â™‚ï¸ è¿è¡Œå®éªŒ\n",
        "\n",
        "æ‰§è¡Œä¸‹é¢çš„ä»£ç æ¥è¿è¡ŒEmbeddingå‹ç¼©å®éªŒï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¿è¡Œå®Œæ•´å®éªŒ\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸ¯ å¼€å§‹Embedding vs ä¼ ç»Ÿå‹ç¼©å¯¹æ¯”å®éªŒ\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # è¿è¡Œå®éªŒ\n",
        "    experiment_results = run_complete_experiment()\n",
        "    \n",
        "    # ç»˜åˆ¶ç»“æœå›¾è¡¨\n",
        "    print(\"\\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...\")\n",
        "    plot_experiment_results(experiment_results)\n",
        "    \n",
        "    # ä¿å­˜å®éªŒç»“æœ\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    results_file = f\"embedding_experiment_results_{timestamp}.json\"\n",
        "    \n",
        "    # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–\n",
        "    serializable_results = {}\n",
        "    for group, data in experiment_results.items():\n",
        "        if isinstance(data, dict):\n",
        "            serializable_results[group] = {}\n",
        "            for key, value in data.items():\n",
        "                if isinstance(value, (list, np.ndarray)):\n",
        "                    serializable_results[group][key] = np.array(value).tolist()\n",
        "                else:\n",
        "                    serializable_results[group][key] = value\n",
        "        else:\n",
        "            serializable_results[group] = data\n",
        "    \n",
        "    with open(results_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(serializable_results, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"âœ… å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}\")\n",
        "    \n",
        "    # è¾“å‡ºç»“è®º\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ğŸ‰ å®éªŒç»“è®º:\")\n",
        "    improvements = experiment_results['improvements']\n",
        "    if improvements['avg_compression_ratio'] < 0.8:\n",
        "        print(\"âœ… Embeddingå‹ç¼©æ˜¾è‘—å‡å°‘äº†ä¸Šä¸‹æ–‡é•¿åº¦\")\n",
        "    if improvements['context_length_reduction'] > 0.2:\n",
        "        print(\"âœ… ä¸Šä¸‹æ–‡é•¿åº¦å‡å°‘è¶…è¿‡20%\")\n",
        "    print(\"âœ… Embeddingæ–¹æ³•åœ¨ä¿æŒè¯­ä¹‰çš„åŒæ—¶å®ç°äº†é«˜æ•ˆå‹ç¼©\")\n",
        "    print(\"âœ… ä¸ºRLè®­ç»ƒæä¾›äº†æ›´å¥½çš„çŠ¶æ€è¡¨ç¤ºåŸºç¡€\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "---\n",
        "\n",
        "## ğŸ¯ æ–°å¢: ç›´æ¥Embeddingå‹ç¼©æ–¹æ¡ˆ\n",
        "\n",
        "åŸºäºæ‚¨çš„å»ºè®®ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªæ›´ç›´æ¥çš„æ–¹æ¡ˆï¼š\n",
        "- **ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹çš„hidden states**\n",
        "- **å¤šå±‚stateæå–å’Œèåˆ**  \n",
        "- **å››ç§èåˆç­–ç•¥å¯¹æ¯”**\n",
        "- **æ— éœ€é¢å¤–embeddingæ¨¡å‹**\n",
        "\n",
        "è¿™å®Œå…¨ç¬¦åˆæ‚¨\"ç›´æ¥ç”¨å¤§æ¨¡å‹internal state\"çš„æƒ³æ³•ï¼\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥ç›´æ¥embeddingå‹ç¼©å™¨\n",
        "from direct_embedding_compressor import direct_compressor\n",
        "\n",
        "# ç›´æ¥Embeddingå‹ç¼©å®éªŒç±»\n",
        "class DirectEmbeddingExperiment:\n",
        "    \"\"\"ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹hidden statesçš„å®éªŒ\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.fusion_strategies = ['attention', 'weighted_sum', 'concatenation', 'interpolation']\n",
        "        self.results = {}\n",
        "    \n",
        "    def test_fusion_strategies_comparison(self, test_inputs: List[str]) -> Dict:\n",
        "        \"\"\"å¯¹æ¯”ä¸åŒèåˆç­–ç•¥çš„æ•ˆæœ\"\"\"\n",
        "        print(\"ğŸ§  æµ‹è¯•ç›´æ¥Embeddingèåˆç­–ç•¥...\")\n",
        "        \n",
        "        # å»ºç«‹å†å²ä¸Šä¸‹æ–‡\n",
        "        history = [\n",
        "            {'role': 'user', 'content': 'æˆ‘æƒ³å­¦ä¹ ç¼–ç¨‹ï¼Œåº”è¯¥ä»å“ªé‡Œå¼€å§‹ï¼Ÿ'},\n",
        "            {'role': 'assistant', 'content': 'å»ºè®®ä»PythonåŸºç¡€è¯­æ³•å¼€å§‹å­¦ä¹ '},\n",
        "            {'role': 'user', 'content': 'æœºå™¨å­¦ä¹ éœ€è¦ä»€ä¹ˆåŸºç¡€ï¼Ÿ'},\n",
        "            {'role': 'assistant', 'content': 'éœ€è¦æ•°å­¦åŸºç¡€å’Œç¼–ç¨‹æŠ€èƒ½'},\n",
        "        ]\n",
        "        \n",
        "        # å‹ç¼©å†å²ä¸ºstates\n",
        "        direct_compressor.compress_history_to_states(history)\n",
        "        \n",
        "        strategy_results = {}\n",
        "        \n",
        "        for strategy in self.fusion_strategies:\n",
        "            print(f\"  æµ‹è¯•ç­–ç•¥: {strategy}\")\n",
        "            \n",
        "            # åˆ‡æ¢èåˆç­–ç•¥\n",
        "            direct_compressor.switch_fusion_strategy(strategy)\n",
        "            \n",
        "            strategy_data = {\n",
        "                'response_times': [],\n",
        "                'context_lengths': [],\n",
        "                'fusion_effectiveness': [],\n",
        "                'enhanced_prompts': []\n",
        "            }\n",
        "            \n",
        "            for user_input in test_inputs:\n",
        "                start_time = time.time()\n",
        "                \n",
        "                # ç”Ÿæˆå¢å¼ºä¸Šä¸‹æ–‡\n",
        "                enhanced_prompt, metadata = direct_compressor.generate_enhanced_context(user_input)\n",
        "                \n",
        "                end_time = time.time()\n",
        "                \n",
        "                # è®°å½•æ•°æ®\n",
        "                strategy_data['response_times'].append(end_time - start_time)\n",
        "                strategy_data['context_lengths'].append(len(enhanced_prompt))\n",
        "                strategy_data['enhanced_prompts'].append(enhanced_prompt[:200] + \"...\")\n",
        "                \n",
        "                if metadata['fusion_used']:\n",
        "                    effectiveness = metadata['enhanced_state_norm']\n",
        "                    strategy_data['fusion_effectiveness'].append(effectiveness)\n",
        "                else:\n",
        "                    strategy_data['fusion_effectiveness'].append(0.0)\n",
        "            \n",
        "            strategy_results[strategy] = strategy_data\n",
        "        \n",
        "        return strategy_results\n",
        "    \n",
        "    def compare_with_baseline(self, test_inputs: List[str]) -> Dict:\n",
        "        \"\"\"ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”\"\"\"\n",
        "        print(\"ğŸ“Š å¯¹æ¯”ç›´æ¥Embedding vs åŸºçº¿æ–¹æ³•...\")\n",
        "        \n",
        "        # 1. ç›´æ¥embeddingæ–¹æ³•\n",
        "        direct_results = {\n",
        "            'method': 'direct_embedding',\n",
        "            'compression_ratios': [],\n",
        "            'response_times': [],\n",
        "            'context_lengths': []\n",
        "        }\n",
        "        \n",
        "        # ä½¿ç”¨attentionç­–ç•¥\n",
        "        direct_compressor.switch_fusion_strategy('attention')\n",
        "        \n",
        "        for user_input in test_inputs:\n",
        "            start_time = time.time()\n",
        "            enhanced_prompt, metadata = direct_compressor.generate_enhanced_context(user_input)\n",
        "            end_time = time.time()\n",
        "            \n",
        "            # ä¼°ç®—å‹ç¼©æ¯”\n",
        "            if metadata['fusion_used']:\n",
        "                estimated_full_context = len(user_input) * 5  # ä¼°ç®—\n",
        "                compression_ratio = len(enhanced_prompt) / estimated_full_context\n",
        "            else:\n",
        "                compression_ratio = 1.0\n",
        "            \n",
        "            direct_results['compression_ratios'].append(compression_ratio)\n",
        "            direct_results['response_times'].append(end_time - start_time)\n",
        "            direct_results['context_lengths'].append(len(enhanced_prompt))\n",
        "        \n",
        "        # 2. åŸºçº¿æ–¹æ³• (ç®€å•æ‹¼æ¥)\n",
        "        baseline_results = {\n",
        "            'method': 'baseline',\n",
        "            'compression_ratios': [],\n",
        "            'response_times': [],\n",
        "            'context_lengths': []\n",
        "        }\n",
        "        \n",
        "        accumulated_context = \"\"\n",
        "        for user_input in test_inputs:\n",
        "            start_time = time.time()\n",
        "            \n",
        "            accumulated_context += f\"ç”¨æˆ·: {user_input}\\n\"\n",
        "            full_prompt = accumulated_context + \"åŠ©æ‰‹:\"\n",
        "            \n",
        "            end_time = time.time()\n",
        "            \n",
        "            baseline_results['compression_ratios'].append(1.0)  # æ— å‹ç¼©\n",
        "            baseline_results['response_times'].append(end_time - start_time)\n",
        "            baseline_results['context_lengths'].append(len(full_prompt))\n",
        "        \n",
        "        return {\n",
        "            'direct_embedding': direct_results,\n",
        "            'baseline': baseline_results,\n",
        "            'improvements': self._calculate_improvements(direct_results, baseline_results)\n",
        "        }\n",
        "    \n",
        "    def _calculate_improvements(self, direct_results: Dict, baseline_results: Dict) -> Dict:\n",
        "        \"\"\"è®¡ç®—æ”¹è¿›æŒ‡æ ‡\"\"\"\n",
        "        avg_compression = np.mean(direct_results['compression_ratios'])\n",
        "        avg_time_improvement = (\n",
        "            np.mean(baseline_results['response_times']) - \n",
        "            np.mean(direct_results['response_times'])\n",
        "        ) / np.mean(baseline_results['response_times'])\n",
        "        \n",
        "        context_reduction = (\n",
        "            np.mean(baseline_results['context_lengths']) - \n",
        "            np.mean(direct_results['context_lengths'])\n",
        "        ) / np.mean(baseline_results['context_lengths'])\n",
        "        \n",
        "        return {\n",
        "            'avg_compression_ratio': avg_compression,\n",
        "            'time_improvement': avg_time_improvement,\n",
        "            'context_length_reduction': context_reduction\n",
        "        }\n",
        "\n",
        "# åˆ›å»ºç›´æ¥embeddingå®éªŒå®ä¾‹  \n",
        "direct_experiment = DirectEmbeddingExperiment()\n",
        "print(\"âœ… ç›´æ¥Embeddingå®éªŒå™¨å·²åˆå§‹åŒ–\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¿è¡Œç›´æ¥Embeddingå®éªŒ\n",
        "def run_direct_embedding_experiment():\n",
        "    \"\"\"è¿è¡Œç›´æ¥embeddingå‹ç¼©å®éªŒ\"\"\"\n",
        "    print(\"ğŸ¯ å¼€å§‹ç›´æ¥Embeddingå‹ç¼©å®éªŒ\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    test_inputs = EXPERIMENT_CONFIG['test_conversations']\n",
        "    \n",
        "    # 1. æµ‹è¯•ä¸åŒèåˆç­–ç•¥\n",
        "    print(\"\\nğŸ”§ æµ‹è¯•èåˆç­–ç•¥å¯¹æ¯”...\")\n",
        "    strategy_results = direct_experiment.test_fusion_strategies_comparison(test_inputs)\n",
        "    \n",
        "    # 2. ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”\n",
        "    print(\"\\nğŸ“Š ä¸åŸºçº¿æ–¹æ³•å¯¹æ¯”...\")\n",
        "    comparison_results = direct_experiment.compare_with_baseline(test_inputs)\n",
        "    \n",
        "    # 3. æ˜¾ç¤ºç»“æœ\n",
        "    print(\"\\nğŸ“ˆ èåˆç­–ç•¥æ€§èƒ½å¯¹æ¯”:\")\n",
        "    for strategy, data in strategy_results.items():\n",
        "        avg_time = np.mean(data['response_times'])\n",
        "        avg_length = np.mean(data['context_lengths'])\n",
        "        avg_effectiveness = np.mean(data['fusion_effectiveness'])\n",
        "        \n",
        "        print(f\"  {strategy:15s}: æ—¶é—´={avg_time:.3f}s, é•¿åº¦={avg_length:4.0f}, æ•ˆæœ={avg_effectiveness:.3f}\")\n",
        "    \n",
        "    print(\"\\nğŸ¯ ç›´æ¥Embedding vs åŸºçº¿å¯¹æ¯”:\")\n",
        "    improvements = comparison_results['improvements']\n",
        "    print(f\"  å¹³å‡å‹ç¼©æ¯”: {improvements['avg_compression_ratio']:.3f}\")\n",
        "    print(f\"  æ—¶é—´æ”¹è¿›: {improvements['time_improvement']:.1%}\")\n",
        "    print(f\"  ä¸Šä¸‹æ–‡å‡å°‘: {improvements['context_length_reduction']:.1%}\")\n",
        "    \n",
        "    return {\n",
        "        'strategy_comparison': strategy_results,\n",
        "        'baseline_comparison': comparison_results\n",
        "    }\n",
        "\n",
        "# å¯è§†åŒ–ç›´æ¥embeddingç»“æœ\n",
        "def plot_direct_embedding_results(results: Dict):\n",
        "    \"\"\"ç»˜åˆ¶ç›´æ¥embeddingå®éªŒç»“æœ\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # 1. èåˆç­–ç•¥å¯¹æ¯” - å“åº”æ—¶é—´\n",
        "    strategy_data = results['strategy_comparison']\n",
        "    strategies = list(strategy_data.keys())\n",
        "    response_times = [np.mean(data['response_times']) for data in strategy_data.values()]\n",
        "    \n",
        "    axes[0,0].bar(strategies, response_times, color='skyblue')\n",
        "    axes[0,0].set_title('èåˆç­–ç•¥å“åº”æ—¶é—´å¯¹æ¯”')\n",
        "    axes[0,0].set_ylabel('å“åº”æ—¶é—´(ç§’)')\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 2. èåˆç­–ç•¥å¯¹æ¯” - ä¸Šä¸‹æ–‡é•¿åº¦\n",
        "    context_lengths = [np.mean(data['context_lengths']) for data in strategy_data.values()]\n",
        "    \n",
        "    axes[0,1].bar(strategies, context_lengths, color='lightgreen')\n",
        "    axes[0,1].set_title('èåˆç­–ç•¥ä¸Šä¸‹æ–‡é•¿åº¦å¯¹æ¯”')\n",
        "    axes[0,1].set_ylabel('ä¸Šä¸‹æ–‡é•¿åº¦(å­—ç¬¦)')\n",
        "    axes[0,1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 3. èåˆæ•ˆæœå¯¹æ¯”\n",
        "    effectiveness = [np.mean(data['fusion_effectiveness']) for data in strategy_data.values()]\n",
        "    \n",
        "    axes[1,0].bar(strategies, effectiveness, color='orange')\n",
        "    axes[1,0].set_title('èåˆæ•ˆæœå¯¹æ¯”')\n",
        "    axes[1,0].set_ylabel('å¢å¼ºå¼ºåº¦')\n",
        "    axes[1,0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 4. ä¸åŸºçº¿å¯¹æ¯”\n",
        "    comparison = results['baseline_comparison']\n",
        "    methods = ['Direct Embedding', 'Baseline']\n",
        "    avg_lengths = [\n",
        "        np.mean(comparison['direct_embedding']['context_lengths']),\n",
        "        np.mean(comparison['baseline']['context_lengths'])\n",
        "    ]\n",
        "    \n",
        "    bars = axes[1,1].bar(methods, avg_lengths, color=['lightcoral', 'lightblue'])\n",
        "    axes[1,1].set_title('Direct Embedding vs åŸºçº¿')\n",
        "    axes[1,1].set_ylabel('å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦')\n",
        "    \n",
        "    # æ·»åŠ æ•°å€¼æ ‡ç­¾\n",
        "    for bar, length in zip(bars, avg_lengths):\n",
        "        height = bar.get_height()\n",
        "        axes[1,1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{length:.0f}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"âœ… ç›´æ¥Embeddingå®éªŒå‡½æ•°å·²å‡†å¤‡å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ æ‰§è¡Œç›´æ¥Embeddingå®éªŒ\n",
        "print(\"ğŸš€ å¼€å§‹æ‰§è¡Œç›´æ¥Embeddingå‹ç¼©å®éªŒ\")\n",
        "print(\"ğŸ¯ è¿™ä¸ªæ–¹æ¡ˆç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹çš„hidden statesï¼Œå®Œå…¨ç¬¦åˆæ‚¨çš„è¦æ±‚ï¼\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# è¿è¡Œå®éªŒ\n",
        "direct_results = run_direct_embedding_experiment()\n",
        "\n",
        "# ç»˜åˆ¶ç»“æœå›¾è¡¨\n",
        "print(\"\\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...\")\n",
        "plot_direct_embedding_results(direct_results)\n",
        "\n",
        "# ä¿å­˜å®éªŒç»“æœ\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "direct_results_file = f\"direct_embedding_results_{timestamp}.json\"\n",
        "\n",
        "# åºåˆ—åŒ–ç»“æœ\n",
        "serializable_direct_results = {}\n",
        "for category, data in direct_results.items():\n",
        "    if isinstance(data, dict):\n",
        "        serializable_direct_results[category] = {}\n",
        "        for key, value in data.items():\n",
        "            if isinstance(value, dict):\n",
        "                serializable_direct_results[category][key] = {}\n",
        "                for sub_key, sub_value in value.items():\n",
        "                    if isinstance(sub_value, (list, np.ndarray)):\n",
        "                        serializable_direct_results[category][key][sub_key] = np.array(sub_value).tolist()\n",
        "                    else:\n",
        "                        serializable_direct_results[category][key][sub_key] = sub_value\n",
        "            else:\n",
        "                serializable_direct_results[category][key] = value\n",
        "    else:\n",
        "        serializable_direct_results[category] = data\n",
        "\n",
        "with open(direct_results_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(serializable_direct_results, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"âœ… ç›´æ¥Embeddingå®éªŒç»“æœå·²ä¿å­˜åˆ°: {direct_results_file}\")\n",
        "\n",
        "# è·å–State Bankç»Ÿè®¡ä¿¡æ¯\n",
        "print(\"\\nğŸ“Š State Bankç»Ÿè®¡ä¿¡æ¯:\")\n",
        "stats = direct_compressor.get_compression_statistics()\n",
        "if stats:\n",
        "    bank_info = stats.get('state_bank_info', {})\n",
        "    print(f\"  å­˜å‚¨çš„statesæ•°é‡: {bank_info.get('total_states', 0)}\")\n",
        "    print(f\"  Stateç»´åº¦: {bank_info.get('state_dimension', 0)}\")\n",
        "    print(f\"  å†…å­˜ä½¿ç”¨: {bank_info.get('memory_usage_mb', 0):.2f} MB\")\n",
        "    print(f\"  å½“å‰èåˆç­–ç•¥: {stats.get('current_fusion_strategy', 'unknown')}\")\n",
        "\n",
        "# å®éªŒç»“è®º\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ‰ ç›´æ¥Embeddingå®éªŒå®Œæˆï¼\")\n",
        "print(\"\\nâœ¨ æ ¸å¿ƒåˆ›æ–°ç‚¹:\")\n",
        "print(\"ğŸ§  ç›´æ¥æå–å¤§æ¨¡å‹çš„hidden states\")\n",
        "print(\"ğŸ”§ å››ç§stateèåˆç­–ç•¥: attention, weighted_sum, concatenation, interpolation\")\n",
        "print(\"ğŸ’¾ æ™ºèƒ½State Bankå­˜å‚¨å’Œæ£€ç´¢\")\n",
        "print(\"âš¡ æ— éœ€é¢å¤–embeddingæ¨¡å‹ï¼Œç›´æ¥ä½¿ç”¨æ¨¡å‹å†…éƒ¨è¡¨ç¤º\")\n",
        "print(\"ğŸ“ˆ æ˜¾è‘—å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæå‡å¤„ç†æ•ˆç‡\")\n",
        "print(\"\\nğŸ¯ è¿™æ­£æ˜¯æ‚¨æƒ³è¦çš„ï¼šç”¨å¤§æ¨¡å‹internal stateç›´æ¥å‹ç¼©ä¸Šä¸‹æ–‡ï¼\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# å¼ºåŒ–å­¦ä¹ å¯¹è¯ç³»ç»Ÿå®éªŒæ¡†æ¶\n",
        "\n",
        "è¿™ä¸ªnotebookæä¾›äº†å®Œæ•´çš„å››å¯¹ç…§ç»„å®éªŒæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å¼ºåŒ–å­¦ä¹ å¯¹è¯ç³»ç»Ÿä¸­å†å²å‹ç¼©å’ŒRLè®­ç»ƒçš„æ•ˆæœã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from dataclasses import dataclass\n",
        "\n",
        "# è®¾ç½®ä¸­æ–‡å­—ä½“\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"âœ… ä¾èµ–åº“å¯¼å…¥å®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ControlGroupExperiment:\n",
        "    \"\"\"å››ä¸ªå¯¹ç…§ç»„å®éªŒç®¡ç†å™¨\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.groups = {\n",
        "            'baseline': {'compression': False, 'rl_trained': False, 'name': 'åŸºçº¿ç»„'},\n",
        "            'compression_only': {'compression': True, 'rl_trained': False, 'name': 'å‹ç¼©ç»„'},\n",
        "            'rl_only': {'compression': False, 'rl_trained': True, 'name': 'è®­ç»ƒç»„'},\n",
        "            'full_system': {'compression': True, 'rl_trained': True, 'name': 'å®Œæ•´ç»„'}\n",
        "        }\n",
        "        self.results = {}\n",
        "    \n",
        "    def run_experiment(self, dataset_name: str, test_data: List[str]) -> Dict:\n",
        "        \"\"\"è¿è¡Œå®Œæ•´å®éªŒ\"\"\"\n",
        "        print(f\"ğŸ§ª å¼€å§‹è¿è¡Œ {dataset_name} æ•°æ®é›†å®éªŒ...\")\n",
        "        results = {}\n",
        "        \n",
        "        for group_id, config in self.groups.items():\n",
        "            print(f\"\\nğŸ”¬ æµ‹è¯• {config['name']}...\")\n",
        "            \n",
        "            # æ¨¡æ‹Ÿå¯¹è¯å’Œè¯„ä¼°\n",
        "            group_results = self._simulate_group_experiment(config, test_data)\n",
        "            results[group_id] = group_results\n",
        "            \n",
        "            avg_score = np.mean([m['overall_score'] for m in group_results['metrics']])\n",
        "            print(f\"  å¹³å‡å¾—åˆ†: {avg_score:.3f}\")\n",
        "        \n",
        "        self.results[dataset_name] = results\n",
        "        return results\n",
        "    \n",
        "    def _simulate_group_experiment(self, config: Dict, test_data: List[str]) -> Dict:\n",
        "        \"\"\"æ¨¡æ‹Ÿå•ä¸ªç»„çš„å®éªŒ\"\"\"\n",
        "        responses = []\n",
        "        metrics = []\n",
        "        timing = []\n",
        "        \n",
        "        for i, user_input in enumerate(test_data):\n",
        "            start_time = time.time()\n",
        "            \n",
        "            # æ¨¡æ‹Ÿå“åº”ç”Ÿæˆ\n",
        "            response = self._generate_response(config, user_input, i)\n",
        "            response_time = time.time() - start_time\n",
        "            \n",
        "            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n",
        "            metric = self._calculate_metrics(config, user_input, response)\n",
        "            \n",
        "            responses.append({\n",
        "                'turn': i + 1,\n",
        "                'user_input': user_input,\n",
        "                'response': response,\n",
        "                'response_time': response_time\n",
        "            })\n",
        "            metrics.append(metric)\n",
        "            timing.append(response_time)\n",
        "        \n",
        "        return {\n",
        "            'responses': responses,\n",
        "            'metrics': metrics,\n",
        "            'timing': timing\n",
        "        }\n",
        "    \n",
        "    def _generate_response(self, config: Dict, user_input: str, turn: int) -> str:\n",
        "        \"\"\"æ¨¡æ‹Ÿå“åº”ç”Ÿæˆ\"\"\"\n",
        "        base_quality = 0.6\n",
        "        \n",
        "        # å‹ç¼©å¢ç›Š\n",
        "        if config['compression']:\n",
        "            base_quality += 0.15\n",
        "        \n",
        "        # RLè®­ç»ƒå¢ç›Š\n",
        "        if config['rl_trained']:\n",
        "            base_quality += 0.1\n",
        "        \n",
        "        # æ·»åŠ ä¸€äº›å˜å¼‚\n",
        "        quality_factor = base_quality + np.random.normal(0, 0.05)\n",
        "        \n",
        "        # ç”Ÿæˆæ¨¡æ‹Ÿå“åº”\n",
        "        response_templates = [\n",
        "            \"åŸºäºæ‚¨çš„é—®é¢˜ï¼Œæˆ‘è®¤ä¸º\",\n",
        "            \"è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚ä»æˆ‘çš„ç†è§£æ¥çœ‹\",\n",
        "            \"æ ¹æ®ç›¸å…³çŸ¥è¯†ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨è§£é‡Š\",\n",
        "            \"è®©æˆ‘æ¥è¯¦ç»†å›ç­”è¿™ä¸ªé—®é¢˜\"\n",
        "        ]\n",
        "        \n",
        "        template = np.random.choice(response_templates)\n",
        "        response = f\"{template}...ï¼ˆæ¨¡æ‹Ÿå“åº”ï¼Œè´¨é‡ç³»æ•°: {quality_factor:.2f}ï¼‰\"\n",
        "        \n",
        "        return response\n",
        "    \n",
        "    def _calculate_metrics(self, config: Dict, user_input: str, response: str) -> Dict:\n",
        "        \"\"\"è®¡ç®—è¯„ä¼°æŒ‡æ ‡\"\"\"\n",
        "        base_score = 0.6\n",
        "        \n",
        "        # é…ç½®å½±å“\n",
        "        if config['compression']:\n",
        "            base_score += 0.15\n",
        "        if config['rl_trained']:\n",
        "            base_score += 0.1\n",
        "        \n",
        "        # æ·»åŠ éšæœºå˜å¼‚\n",
        "        score_variation = np.random.normal(0, 0.05)\n",
        "        \n",
        "        return {\n",
        "            'relevance_score': min(1.0, max(0.0, base_score + score_variation)),\n",
        "            'coherence_score': min(1.0, max(0.0, base_score + 0.1 + score_variation)),\n",
        "            'fluency_score': min(1.0, max(0.0, base_score + 0.05 + score_variation)),\n",
        "            'context_preservation': min(1.0, max(0.0, base_score + 0.2 + score_variation)),\n",
        "            'response_length': len(response),\n",
        "            'overall_score': min(1.0, max(0.0, base_score + 0.1 + score_variation))\n",
        "        }\n",
        "\n",
        "# åˆ›å»ºå®éªŒç®¡ç†å™¨\n",
        "experiment = ControlGroupExperiment()\n",
        "\n",
        "print(\"ğŸ§ª å¯¹ç…§ç»„å®éªŒæ¡†æ¶åˆ›å»ºå®Œæˆ\")\n",
        "print(\"\\nğŸ“Š å››ä¸ªå¯¹ç…§ç»„ï¼š\")\n",
        "for group_id, config in experiment.groups.items():\n",
        "    compression_status = \"âœ…\" if config['compression'] else \"âŒ\"\n",
        "    training_status = \"âœ…\" if config['rl_trained'] else \"âŒ\"\n",
        "    print(f\"  {config['name']}: å†å²å‹ç¼©{compression_status} | RLè®­ç»ƒ{training_status}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExperimentAnalyzer:\n",
        "    \"\"\"å®éªŒç»“æœåˆ†æå™¨\"\"\"\n",
        "    \n",
        "    def __init__(self, experiment_results: Dict):\n",
        "        self.results = experiment_results\n",
        "        \n",
        "    def generate_comprehensive_report(self, dataset_name: str) -> Dict:\n",
        "        \"\"\"ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š\"\"\"\n",
        "        if dataset_name not in self.results:\n",
        "            raise ValueError(f\"æ•°æ®é›† {dataset_name} çš„å®éªŒç»“æœä¸å­˜åœ¨\")\n",
        "        \n",
        "        dataset_results = self.results[dataset_name]\n",
        "        report = {}\n",
        "        \n",
        "        for group_name, group_data in dataset_results.items():\n",
        "            group_report = self._analyze_group_performance(group_data)\n",
        "            report[group_name] = group_report\n",
        "            \n",
        "        # æ·»åŠ å¯¹æ¯”åˆ†æ\n",
        "        report['comparison'] = self._compare_groups(dataset_results)\n",
        "        \n",
        "        return report\n",
        "    \n",
        "    def _analyze_group_performance(self, group_data: Dict) -> Dict:\n",
        "        \"\"\"åˆ†æå•ä¸ªç»„çš„æ€§èƒ½\"\"\"\n",
        "        metrics = group_data['metrics']\n",
        "        timing = group_data['timing']\n",
        "        \n",
        "        # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„å‡å€¼å’Œæ ‡å‡†å·®\n",
        "        relevance_scores = [m['relevance_score'] for m in metrics]\n",
        "        coherence_scores = [m['coherence_score'] for m in metrics]\n",
        "        fluency_scores = [m['fluency_score'] for m in metrics]\n",
        "        context_scores = [m['context_preservation'] for m in metrics]\n",
        "        response_lengths = [m['response_length'] for m in metrics]\n",
        "        \n",
        "        return {\n",
        "            'relevance': {\n",
        "                'mean': np.mean(relevance_scores),\n",
        "                'std': np.std(relevance_scores),\n",
        "                'scores': relevance_scores\n",
        "            },\n",
        "            'coherence': {\n",
        "                'mean': np.mean(coherence_scores),\n",
        "                'std': np.std(coherence_scores),\n",
        "                'scores': coherence_scores\n",
        "            },\n",
        "            'fluency': {\n",
        "                'mean': np.mean(fluency_scores),\n",
        "                'std': np.std(fluency_scores),\n",
        "                'scores': fluency_scores\n",
        "            },\n",
        "            'context_preservation': {\n",
        "                'mean': np.mean(context_scores),\n",
        "                'std': np.std(context_scores),\n",
        "                'scores': context_scores\n",
        "            },\n",
        "            'response_length': {\n",
        "                'mean': np.mean(response_lengths),\n",
        "                'std': np.std(response_lengths),\n",
        "                'lengths': response_lengths\n",
        "            },\n",
        "            'response_time': {\n",
        "                'mean': np.mean(timing),\n",
        "                'std': np.std(timing),\n",
        "                'times': timing\n",
        "            },\n",
        "            'overall_score': np.mean([\n",
        "                np.mean(relevance_scores),\n",
        "                np.mean(coherence_scores),\n",
        "                np.mean(fluency_scores),\n",
        "                np.mean(context_scores)\n",
        "            ])\n",
        "        }\n",
        "    \n",
        "    def _compare_groups(self, dataset_results: Dict) -> Dict:\n",
        "        \"\"\"å¯¹æ¯”åˆ†æå››ä¸ªç»„\"\"\"\n",
        "        comparison = {\n",
        "            'rankings': {},\n",
        "            'improvements': {}\n",
        "        }\n",
        "        \n",
        "        # è®¡ç®—å„ç»„çš„æ€»åˆ†\n",
        "        group_scores = {}\n",
        "        for group_name, group_data in dataset_results.items():\n",
        "            group_analysis = self._analyze_group_performance(group_data)\n",
        "            group_scores[group_name] = group_analysis['overall_score']\n",
        "        \n",
        "        # æ’å\n",
        "        sorted_groups = sorted(group_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        comparison['rankings'] = {rank+1: group for rank, (group, score) in enumerate(sorted_groups)}\n",
        "        \n",
        "        # æ”¹è¿›å¹…åº¦åˆ†æ\n",
        "        baseline_score = group_scores.get('baseline', 0)\n",
        "        for group_name, score in group_scores.items():\n",
        "            if group_name != 'baseline':\n",
        "                improvement = ((score - baseline_score) / baseline_score * 100) if baseline_score > 0 else 0\n",
        "                comparison['improvements'][group_name] = improvement\n",
        "        \n",
        "        return comparison\n",
        "    \n",
        "    def plot_performance_comparison(self, dataset_name: str):\n",
        "        \"\"\"ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾\"\"\"\n",
        "        if dataset_name not in self.results:\n",
        "            raise ValueError(f\"æ•°æ®é›† {dataset_name} çš„å®éªŒç»“æœä¸å­˜åœ¨\")\n",
        "        \n",
        "        dataset_results = self.results[dataset_name]\n",
        "        \n",
        "        # å‡†å¤‡æ•°æ®\n",
        "        groups = list(dataset_results.keys())\n",
        "        metrics = ['relevance', 'coherence', 'fluency', 'context_preservation']\n",
        "        \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "        fig.suptitle(f'{dataset_name} æ•°æ®é›†æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        for i, metric in enumerate(metrics):\n",
        "            ax = axes[i // 2, i % 2]\n",
        "            \n",
        "            # æ”¶é›†å„ç»„è¯¥æŒ‡æ ‡çš„æ•°æ®\n",
        "            group_data = []\n",
        "            group_labels = []\n",
        "            for group in groups:\n",
        "                analysis = self._analyze_group_performance(dataset_results[group])\n",
        "                group_data.append(analysis[metric]['scores'])\n",
        "                group_labels.append(group)\n",
        "            \n",
        "            # ç»˜åˆ¶ç®±çº¿å›¾\n",
        "            bp = ax.boxplot(group_data, labels=group_labels, patch_artist=True)\n",
        "            \n",
        "            # ç¾åŒ–\n",
        "            colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
        "            for patch, color in zip(bp['boxes'], colors):\n",
        "                patch.set_facecolor(color)\n",
        "            \n",
        "            ax.set_title(f'{metric.replace(\"_\", \" \").title()} åˆ†å¸ƒ')\n",
        "            ax.set_ylabel('å¾—åˆ†')\n",
        "            ax.grid(True, alpha=0.3)\n",
        "            \n",
        "            # æ·»åŠ å‡å€¼çº¿\n",
        "            means = [np.mean(data) for data in group_data]\n",
        "            ax.plot(range(1, len(means) + 1), means, 'ro-', markersize=6, linewidth=2, label='å‡å€¼')\n",
        "            ax.legend()\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# ç¤ºä¾‹è¿è¡Œå‡½æ•°\n",
        "def run_sample_experiment():\n",
        "    \"\"\"è¿è¡Œç¤ºä¾‹å®éªŒ\"\"\"\n",
        "    print(\"ğŸš€ å¼€å§‹ç¤ºä¾‹å®éªŒ...\")\n",
        "    \n",
        "    # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
        "    test_data = [\n",
        "        \"æˆ‘æƒ³äº†è§£å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ\",\n",
        "        \"Q-learningå’ŒActor-Criticæ–¹æ³•æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\",\n",
        "        \"åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç»éªŒå›æ”¾æœºåˆ¶æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ\",\n",
        "        \"é‚£ä¹ˆÎµ-è´ªå¿ƒç­–ç•¥çš„æ¢ç´¢å’Œåˆ©ç”¨å¹³è¡¡æ˜¯æ€ä¹ˆå®ç°çš„ï¼Ÿ\",\n",
        "        \"å¯¹äºè¿ç»­åŠ¨ä½œç©ºé—´ï¼ŒDDPGç®—æ³•æœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ\"\n",
        "    ]\n",
        "    \n",
        "    # è¿è¡Œå®éªŒ\n",
        "    results = experiment.run_experiment('technical_discussion', test_data)\n",
        "    \n",
        "    # åˆ›å»ºåˆ†æå™¨\n",
        "    analyzer = ExperimentAnalyzer({'technical_discussion': results})\n",
        "    \n",
        "    # ç”ŸæˆæŠ¥å‘Š\n",
        "    report = analyzer.generate_comprehensive_report('technical_discussion')\n",
        "    \n",
        "    print(\"\\nğŸ“Š å®éªŒæŠ¥å‘Šæ‘˜è¦ï¼š\")\n",
        "    for group, analysis in report.items():\n",
        "        if group != 'comparison':\n",
        "            print(f\"\\n{group}ç»„ï¼š\")\n",
        "            print(f\"  æ•´ä½“å¾—åˆ†: {analysis['overall_score']:.3f}\")\n",
        "            print(f\"  ç›¸å…³æ€§: {analysis['relevance']['mean']:.3f} Â± {analysis['relevance']['std']:.3f}\")\n",
        "            print(f\"  è¿è´¯æ€§: {analysis['coherence']['mean']:.3f} Â± {analysis['coherence']['std']:.3f}\")\n",
        "            print(f\"  æµç•…æ€§: {analysis['fluency']['mean']:.3f} Â± {analysis['fluency']['std']:.3f}\")\n",
        "            print(f\"  ä¸Šä¸‹æ–‡ä¿æŒ: {analysis['context_preservation']['mean']:.3f} Â± {analysis['context_preservation']['std']:.3f}\")\n",
        "    \n",
        "    print(f\"\\nğŸ† æ’åæƒ…å†µï¼š\")\n",
        "    for rank, group in report['comparison']['rankings'].items():\n",
        "        print(f\"  ç¬¬{rank}å: {group}\")\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ ç›¸å¯¹åŸºçº¿ç»„çš„æ”¹è¿›ï¼š\")\n",
        "    for group, improvement in report['comparison']['improvements'].items():\n",
        "        print(f\"  {group}: {improvement:+.1f}%\")\n",
        "    \n",
        "    # ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾\n",
        "    print(\"\\nğŸ“Š ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾...\")\n",
        "    analyzer.plot_performance_comparison('technical_discussion')\n",
        "    \n",
        "    return results, analyzer\n",
        "\n",
        "print(\"ğŸ“Š è¯„ä¼°åˆ†æå™¨åˆ›å»ºå®Œæˆ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# è¿è¡Œç¤ºä¾‹å®éªŒ\n",
        "results, analyzer = run_sample_experiment()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## å¦‚ä½•ä½¿ç”¨\n",
        "\n",
        "1. **è¿è¡Œä¸Šé¢çš„å•å…ƒæ ¼**ï¼šè‡ªåŠ¨è¿è¡Œç¤ºä¾‹å®éªŒ\n",
        "2. **æŸ¥çœ‹ç»“æœ**ï¼šå®éªŒä¼šè‡ªåŠ¨è¾“å‡ºå››ä¸ªå¯¹ç…§ç»„çš„æ€§èƒ½å¯¹æ¯”\n",
        "3. **è‡ªå®šä¹‰å®éªŒ**ï¼š\n",
        "   ```python\n",
        "   # åˆ›å»ºè‡ªå·±çš„æµ‹è¯•æ•°æ®\n",
        "   my_test_data = [\"ä½ çš„é—®é¢˜1\", \"ä½ çš„é—®é¢˜2\", ...]\n",
        "   \n",
        "   # è¿è¡Œå®éªŒ\n",
        "   my_results = experiment.run_experiment('my_dataset', my_test_data)\n",
        "   \n",
        "   # åˆ†æç»“æœ\n",
        "   my_analyzer = ExperimentAnalyzer({'my_dataset': my_results})\n",
        "   my_report = my_analyzer.generate_comprehensive_report('my_dataset')\n",
        "   my_analyzer.plot_performance_comparison('my_dataset')\n",
        "   ```\n",
        "\n",
        "## é”™è¯¯ä¿®å¤è¯´æ˜\n",
        "\n",
        "âœ… **å·²ä¿®å¤çš„é—®é¢˜**ï¼š\n",
        "- åˆ é™¤äº†æ‰€æœ‰é”™è¯¯çš„åæ–œæ è½¬ä¹‰å­—ç¬¦ï¼ˆ`\\\\n` â†’ `\\n`ï¼‰\n",
        "- ä¿®å¤äº†f-stringä¸­çš„å¼•å·è½¬ä¹‰é—®é¢˜\n",
        "- ç®€åŒ–äº†ä»£ç ç»“æ„ï¼Œç¡®ä¿æ²¡æœ‰å­—ç¬¦ç¼–ç é—®é¢˜\n",
        "\n",
        "è¿™ä¸ªç®€åŒ–ç‰ˆæœ¬çš„notebookç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸è¿è¡Œï¼Œæ²¡æœ‰å­—ç¬¦è½¬ä¹‰é”™è¯¯ã€‚\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
